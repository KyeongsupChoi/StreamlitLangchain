## LangChain project checklist

### Models
- [x] Choose a **chat model provider + model identifier** (static), or implement **dynamic model selection** at runtime.
- [x] Use a consistent model interface (`init_chat_model` or a provider class) and support:
  - [x] `invoke()` for normal calls
  - [x] `stream()` for progressive UX
  - [x] `batch()` / `batch_as_completed()` for throughput
- [x] Define and document **standard model parameters** you rely on:
  - [x] `model`, `api_key`, `temperature`, `max_tokens`, `timeout`, `max_retries`
- [x] Handle **token usage** tracking with context manager.
- [x] Decide whether your app needs **multimodal** support (content blocks).
- [x] Decide whether you need **reasoning output** surfaced (and at what level).
- [x] Add **rate limiting** if you expect bursts or background jobs.
- [x] Document any **base_url / proxy** requirements (AWS Bedrock endpoints):
  - [ ] **AWS Bedrock configuration**:
    - [ ] Set `region_name` (e.g., `us-east-1`, `us-west-2`)
    - [ ] Configure AWS credentials (one of):
      - [ ] Environment variables: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_SESSION_TOKEN`
      - [ ] AWS credentials file (`~/.aws/credentials`)
      - [ ] IAM role (for EC2/ECS/Lambda execution)
      - [ ] AWS SSO profile
    - [ ] Specify `model_id` for Bedrock models (e.g., `anthropic.claude-3-sonnet-20240229-v1:0`)
    - [ ] Handle cross-region inference if needed (requires specific model ARNs)
  - [ ] **Corporate proxy** configuration (if behind firewall):
    - [ ] Set boto3 proxy via `botocore.config.Config(proxies={'https': 'proxy-url'})`
    - [ ] Or use environment variables: `HTTP_PROXY`, `HTTPS_PROXY`, `NO_PROXY`
    - [ ] Handle proxy authentication if required
  - [ ] **Connection parameters** for AWS endpoints:
    - [ ] `connect_timeout`, `read_timeout`: configure via botocore Config
    - [ ] `max_attempts`: retry logic for API throttling (default 3)
    - [ ] `retry_mode`: standard/adaptive for handling rate limits
  - [ ] Document **environment-specific configurations**:
    - [ ] Different AWS regions per environment (dev/staging/prod)
    - [ ] Different IAM roles/credentials per environment
    - [ ] Model availability by region

### Messages
- [ ] Understand **message fundamentals** (role, content, metadata):
  - [ ] Know the three core components of messages (role, content, metadata)
  - [ ] Understand that messages work consistently across all model providers
- [ ] Choose appropriate **message format** for your use case:
  - [ ] **Text prompts** for:
    - [ ] Single, standalone requests
    - [ ] No conversation history needed
    - [ ] Minimal code complexity
  - [ ] **Message prompts** for:
    - [ ] Multi-turn conversations
    - [ ] Multimodal content (images, audio, files)
    - [ ] System instructions and context
  - [ ] **Dictionary format** for OpenAI-compatible APIs
- [ ] Implement **message types** correctly:
  - [ ] **SystemMessage**: Define model behavior and role
    - [ ] Set tone and personality
    - [ ] Establish response guidelines
    - [ ] Provide context and constraints
  - [ ] **HumanMessage**: Represent user input
    - [ ] Support text content
    - [ ] Add optional metadata (name, id) for tracking
    - [ ] Handle multimodal content if needed
  - [ ] **AIMessage**: Handle model responses
    - [ ] Access `.text` for simple content
    - [ ] Access `.content` for raw content
    - [ ] Process `.tool_calls` when using tools
    - [ ] Check `.usage_metadata` for token counts
    - [ ] Review `.response_metadata` for provider-specific data
  - [ ] **ToolMessage**: Return tool execution results
    - [ ] Match `tool_call_id` from AIMessage
    - [ ] Provide stringified tool output in `content`
    - [ ] Use `artifact` field for supplementary data not sent to model
- [ ] Handle **message metadata** appropriately:
  - [ ] Use `name` field to identify different users/speakers
  - [ ] Use `id` field for tracing and debugging
  - [ ] Track `usage_metadata` for token counting and cost management
  - [ ] Access `response_metadata` for provider-specific information
- [ ] Work with **message content** correctly:
  - [ ] Understand `content` attribute (loosely-typed: string or list)
  - [ ] Use `content_blocks` property for type-safe standard representation
  - [ ] Choose between provider-native format vs standard content blocks
- [ ] Implement **multimodal content** if needed:
  - [ ] **Image content**: support URL, base64, or file_id formats
  - [ ] **Audio content**: support base64 or file_id formats
  - [ ] **Video content**: support base64 or file_id formats
  - [ ] **File content**: support PDF and documents (URL, base64, file_id)
  - [ ] Specify correct MIME types for all media
  - [ ] Check model provider support for each media type
- [ ] Understand **content block types**:
  - [ ] **Core blocks**:
    - [ ] TextContentBlock for standard text output
    - [ ] ReasoningContentBlock for model reasoning steps
  - [ ] **Multimodal blocks**:
    - [ ] ImageContentBlock, AudioContentBlock, VideoContentBlock
    - [ ] FileContentBlock for PDFs and documents
    - [ ] PlainTextContentBlock for .txt and .md files
  - [ ] **Tool calling blocks**:
    - [ ] ToolCall for function calls
    - [ ] ToolCallChunk for streaming tool calls
    - [ ] InvalidToolCall for error handling
  - [ ] **Server-side tool blocks** (if using server-side execution):
    - [ ] ServerToolCall, ServerToolCallChunk, ServerToolResult
- [ ] Handle **streaming messages** correctly:
  - [ ] Process `AIMessageChunk` objects during streaming
  - [ ] Combine chunks into full messages (using `+` operator)
  - [ ] Handle tool call chunks that accumulate into full calls
- [ ] Manage **conversation state** with messages:
  - [ ] Build message lists that alternate HumanMessage and AIMessage
  - [ ] Include SystemMessage at the beginning when needed
  - [ ] Insert ToolMessage after AIMessage with tool_calls
  - [ ] Ensure message history remains valid for provider requirements

### Tool calling
- [x] Define tools with **clear names, descriptions, and schemas** (they become part of the model's prompt):
  - [x] **Tool naming**:
    - [x] Use verb_noun format (e.g., `get_weather`, `search_database`, `send_email`)
    - [x] Be specific and descriptive (avoid generic names like `tool1`, `helper`)
    - [x] Use snake_case for consistency with LangChain conventions
    - [x] Keep names concise but unambiguous (model sees these in prompt)
  - [x] **Tool descriptions**:
    - [x] Write clear, imperative descriptions explaining what the tool does
    - [x] Include when/why to use the tool (helps model decision-making)
    - [x] Specify any constraints or limitations (API rate limits, data freshness, etc.)
    - [x] Keep descriptions concise but complete (they consume prompt tokens)
  - [ ] **Schema design**:
    - [ ] Use Pydantic models or `@tool` decorator for automatic schema generation
    - [ ] Define all required vs optional parameters explicitly
    - [ ] Add field descriptions for each parameter (shown to model)
    - [ ] Use appropriate types (str, int, float, bool, enums, lists, nested objects)
    - [ ] Set sensible defaults for optional parameters
    - [ ] Add validation constraints (min/max, regex patterns, allowed values)
  - [ ] **Parameter documentation**:
    - [ ] Describe format expectations (e.g., "ISO 8601 date", "valid email address")
    - [ ] Provide examples in descriptions when format is complex
    - [ ] Clarify units for numeric parameters (seconds, meters, USD, etc.)
    - [ ] Document relationships between parameters if applicable
  - [ ] **Return value specification**:
    - [ ] Document what the tool returns (type and structure)
    - [ ] Explain possible error messages or failure modes
    - [ ] Indicate if tool has side effects (writes data, sends notifications)
- [ ] Bind tools with `bind_tools(...)` (and optionally):
  - [ ] force tool use via `tool_choice`
  - [ ] enable/disable `parallel_tool_calls`
- [ ] Implement the **tool execution loop** correctly:
  - [ ] model produces tool calls
  - [ ] execute tool(s)
  - [ ] return results as `ToolMessage` with matching `tool_call_id`
  - [ ] re-invoke model with updated message history
- [ ] Support **streaming tool calls** if you stream responses (tool call chunks accumulate into full calls).

### Structured output
- [ ] Decide if outputs must be **schema-constrained**.
- [ ] Pick a schema type:
  - [ ] Pydantic (validation + rich metadata)
  - [ ] TypedDict (lightweight, no runtime validation)
  - [ ] JSON Schema (interop/control)
- [ ] Choose/confirm the **structured output method** strategy:
  - [ ] provider-native (`json_schema`-style)
  - [ ] tool/function-calling derived structure
  - [ ] json-mode style (prompt-based constraints)
- [ ] Decide whether you need `include_raw=True` (store raw message + parsed + error).

### Agents
- [ ] Decide whether you need an **agent loop** (vs direct model calls).
- [ ] Define the **stop condition** (final answer vs iteration limit).
- [x] Provide a **system prompt** (string or `SystemMessage`), or implement:
  - [ ] dynamic system prompt middleware
- [ ] Define tools as either:
  - [ ] static tools (fixed list)
  - [ ] dynamic tools (filtered or registered at runtime)
- [ ] If using dynamic tools, implement one of:
  - [ ] filtering pre-registered tools (by state/store/context)
  - [ ] runtime registration with BOTH:
    - [ ] `wrap_model_call` to add tools
    - [ ] `wrap_tool_call` to execute tools

### Middleware (production controls)
- [ ] Add `wrap_model_call` middleware for:
  - [ ] dynamic model selection/routing
  - [ ] tool filtering / tool gating
  - [ ] request shaping (timeouts, params, overrides)
- [ ] Add `wrap_tool_call` middleware for:
  - [ ] tool error handling (convert exceptions to model-visible messages)
  - [ ] tool substitution / runtime dispatch
- [ ] Decide what agent **state** you need beyond messages:
  - [ ] via middleware state schema
  - [ ] or `state_schema` for tool access

### Memory & conversation state
- [x] Decide on **short-term memory** approach (message state).
- [ ] Decide on **persistence** (in-memory vs durable store) if conversations must survive restarts.
- [ ] Standardize identifiers like **thread/conversation IDs**.

### Streaming UX
- [ ] Decide what you stream:
  - [ ] tokens/text
  - [ ] intermediate agent steps
  - [ ] tool call progress
  - [ ] semantic events (`astream_events`)
- [ ] Ensure every step that touches model output is **stream-compatible** (or explicitly non-streaming).

